{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_03_Attention.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMipOiGNLbe3e+htWqs+NxK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alxiom/Basic-NLP/blob/main/NLP_03_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbCX7udCJi-8",
        "outputId": "427260c7-5111-4d76-9cc0-c13efe6f16f7"
      },
      "source": [
        "!pip install tokenizers\n",
        "!git clone https://github.com/alxiom/Basic-NLP.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.3)\n",
            "fatal: destination path 'Basic-NLP' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLYsE8TdJwSN"
      },
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as ftn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tokenizers import CharBPETokenizer\n",
        "from bokeh.layouts import column\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "\n",
        "output_notebook()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa6cnjhjJyh6"
      },
      "source": [
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "special = [\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\", \"<sep>\", \"<cls>\", \"<mask>\"]\n",
        "device = \"cpu\"\n",
        "\n",
        "train_seq2seq_attention = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jhk01MPKBD6"
      },
      "source": [
        "tokenizer = CharBPETokenizer(vocab=\"Basic-NLP/data/vocab.json\", merges=\"Basic-NLP/data/merges.txt\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjfXH-FtKG10",
        "outputId": "a28e86f2-0fe9-46e4-ef37-b608d67c3ca6"
      },
      "source": [
        "train_data = pd.read_csv(\"Basic-NLP/data/chat_sample.csv\", header=0)\n",
        "print(train_data.head(5))\n",
        "print(len(train_data))\n",
        "print(\"--\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Q              A\n",
            "0       죽을거 같네  나쁜 생각 하지 마세요.\n",
            "1      내일 시험이야    컨디션 조절 하세요.\n",
            "2  정말.내 자신이 싫다    자신은 사랑해주세요.\n",
            "3      이별후 네달째  바쁘게 살면서 잊어가요.\n",
            "4      쌍커풀 해볼까       눈은 기본이죠.\n",
            "128\n",
            "--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJVhwkl6KMn7"
      },
      "source": [
        "query_tokens = []\n",
        "answer_tokens = []\n",
        "for i in range(len(train_data)):\n",
        "    row = train_data.loc[i]\n",
        "    query = row[\"Q\"]\n",
        "    answer = row[\"A\"]\n",
        "\n",
        "    tokenize_query = tokenizer.encode(query)\n",
        "    tokenize_answer = tokenizer.encode(answer)\n",
        "\n",
        "    query_tokens.append(tokenize_query.ids)\n",
        "    answer_tokens.append(tokenize_answer.ids)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydP7zRCfKgXt"
      },
      "source": [
        "class LoadDataset(Dataset):\n",
        "\n",
        "    def __init__(self, x_data, y_data):\n",
        "        super(LoadDataset, self).__init__()\n",
        "        self.x_data = x_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.x_data[item], self.y_data[item]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y_data)\n",
        "\n",
        "\n",
        "class MaxPadBatch:\n",
        "\n",
        "    def __init__(self, max_len=24):\n",
        "        super(MaxPadBatch, self).__init__()\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        batch_x = []\n",
        "        batch_y = []\n",
        "        for x, y in batch:\n",
        "            batch_x.append(torch.tensor(x).long())\n",
        "            batch_y.append(torch.tensor([special.index(\"<bos>\")] + y + [special.index(\"<eos>\")]).long())\n",
        "        pad_index = special.index(\"<pad>\")\n",
        "        pad_x = [ftn.pad(item, [0, self.max_len - item.shape[0]], value=pad_index).detach() for item in batch_x]\n",
        "        pad_y = [ftn.pad(item, [0, self.max_len - item.shape[0]], value=pad_index).detach() for item in batch_y]\n",
        "        return torch.stack(pad_x), torch.stack(pad_y), len(batch)\n",
        "\n",
        "\n",
        "max_seq_length = 20\n",
        "chat_dataset = LoadDataset(query_tokens, answer_tokens)\n",
        "chat_data_loader = DataLoader(chat_dataset, batch_size=32, collate_fn=MaxPadBatch(max_seq_length))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ9sb13pKilQ"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, embedding_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.GRU(self.embedding_size, self.hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x, embedding):\n",
        "        # x: [batch, seq_length]\n",
        "        x = embedding(x)\n",
        "        x, hidden = self.rnn(x)\n",
        "        return x, hidden"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-AUVqi_KlDG"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, output_size, embedding_size, hidden_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.GRU(self.embedding_size, self.hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x, hidden, embedding):\n",
        "        # x: [batch] --> need second dimension as 1\n",
        "        # hidden: [encoder_layers = 1, batch, hidden_dim]\n",
        "        x = x.unsqueeze(1)\n",
        "        x = embedding(x)\n",
        "        x, hidden = self.rnn(x, hidden)\n",
        "        return x, hidden"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPTNgbvxKmCn"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, encoder_output, decoder_output):\n",
        "        # 이번 decoder 출력이 encoder 모든 출력들과 얼마나 강한 관계가 있는지 측정\n",
        "        # 이번 decoder 출력과 encoder 모든 출력과 dot product 실행 --> sequence of scala (=attention score)\n",
        "        # attention score --> softmax --> attention weight\n",
        "        # 위에서 구한 강도에 따라서 encoder 모든 출력을 weight sum --> context_vector\n",
        "        attention_score = torch.bmm(decoder_output, encoder_output.transpose(1, 2))\n",
        "        attention_weight = self.softmax(attention_score)\n",
        "        context_vector = torch.bmm(attention_weight, encoder_output)\n",
        "        return context_vector"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk783WUYKol3"
      },
      "source": [
        "class Seq2SeqAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder, attention):\n",
        "        super(Seq2SeqAttention, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(self.encoder.input_size, self.encoder.embedding_size)\n",
        "        self.target_vocab_size = self.decoder.output_size\n",
        "        self.linear = nn.Linear(self.encoder.hidden_size + self.decoder.hidden_size, self.target_vocab_size)\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing=0.5):\n",
        "        # source: [batch, seq_length]\n",
        "        # target: [batch, seq_length]\n",
        "        batch_size = target.shape[0]\n",
        "        target_seq_length = target.shape[1]\n",
        "\n",
        "        encoder_output, hidden = self.encoder(source, self.embedding)\n",
        "        decoder_input = torch.tensor([special.index(\"<bos>\")] * batch_size).long()\n",
        "\n",
        "        attention_outputs = torch.zeros(batch_size, target_seq_length, self.target_vocab_size)\n",
        "        for t in range(1, target_seq_length):\n",
        "            decoder_output, hidden = self.decoder(decoder_input, hidden, self.embedding)\n",
        "            # encoder output, decoder output 두 값을 이용하여 지금 decoding 할 context 생성\n",
        "            # decoder output, context 이용하여 attention 적용된 output 도출\n",
        "            # attention output 사용하여 greedy decoding\n",
        "            context = self.attention(encoder_output, decoder_output)\n",
        "            attention_output = self.linear(torch.cat([decoder_output, context], dim=2).squeeze(1))\n",
        "            attention_outputs[:, t, :] = attention_output\n",
        "            teacher = target[:, t]\n",
        "            top1 = attention_output.argmax(1)\n",
        "            decoder_input = teacher if random.random() < teacher_forcing else top1\n",
        "        return attention_outputs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4srYREhKrFw",
        "outputId": "fdafbefe-bb6b-444a-fc4d-0d1e29a8dc5d"
      },
      "source": [
        "embedding_dim = 32\n",
        "hidden_dim = 32\n",
        "enc = Encoder(tokenizer.get_vocab_size(), embedding_dim, hidden_dim)\n",
        "dec = Decoder(tokenizer.get_vocab_size(), embedding_dim, hidden_dim)\n",
        "att = Attention()\n",
        "seq2seq_att = Seq2SeqAttention(enc, dec, att)\n",
        "\n",
        "decode_test = torch.tensor([[special.index(\"<bos>\")] + [special.index(\"<pad>\")] * (max_seq_length - 1)]).long()\n",
        "\n",
        "if train_seq2seq_attention:\n",
        "    learning_rate = 2e-3\n",
        "    optimizer = torch.optim.Adam(seq2seq_att.parameters(), lr=learning_rate)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=special.index(\"<pad>\"))\n",
        "\n",
        "    for epoch in range(300):\n",
        "        seq2seq_att.train()\n",
        "        epoch_loss = 0.0\n",
        "        for batch_source, batch_target, batch_length in chat_data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            seq2seq_attention_output = seq2seq_att(batch_source, batch_target)\n",
        "\n",
        "            seq2seq_attention_output_dim = seq2seq_attention_output.shape[-1]\n",
        "            seq2seq_attention_output_drop = seq2seq_attention_output[:, 1:, :].reshape(-1, seq2seq_attention_output_dim)\n",
        "            batch_target_drop = batch_target[:, 1:].reshape(-1)\n",
        "            loss = criterion(seq2seq_attention_output_drop, batch_target_drop)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item() / batch_length\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"{epoch} epoch loss: {epoch_loss:.4f} / ppl: {math.exp(epoch_loss):.4f}\")\n",
        "            seq2seq_att.eval()\n",
        "            test = \"썸 타는 것도 귀찮아.\"\n",
        "            test_token = tokenizer.encode(test)\n",
        "            test_tensor = torch.tensor(test_token.ids).long().unsqueeze(0)\n",
        "            test_output = seq2seq_att(test_tensor, decode_test, 0.0)[:, 1:, :].squeeze(0).argmax(1).detach().tolist()\n",
        "            recover_test_output = tokenizer.decode(test_output)\n",
        "            print(recover_test_output.split(\"<eos>\")[0])\n",
        "            test = \"죽을거 같네\"\n",
        "            test_token = tokenizer.encode(test)\n",
        "            test_tensor = torch.tensor(test_token.ids).long().unsqueeze(0)\n",
        "            test_output = seq2seq_att(test_tensor, decode_test, 0.0)[:, 1:, :].squeeze(0).argmax(1).detach().tolist()\n",
        "            recover_test_output = tokenizer.decode(test_output)\n",
        "            print(recover_test_output.split(\"<eos>\")[0])\n",
        "            test = \"한심해서 죽고싶다\"\n",
        "            test_token = tokenizer.encode(test)\n",
        "            test_tensor = torch.tensor(test_token.ids).long().unsqueeze(0)\n",
        "            test_output = seq2seq_att(test_tensor, decode_test, 0.0)[:, 1:, :].squeeze(0).argmax(1).detach().tolist()\n",
        "            recover_test_output = tokenizer.decode(test_output)\n",
        "            print(recover_test_output.split(\"<eos>\")[0])\n",
        "        \n",
        "    torch.save(seq2seq_att.state_dict(), \"Basic-NLP/checkpoint/seq2seq_attention.pt\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 epoch loss: 0.9099 / ppl: 2.4840\n",
            "서서 꿨지났군요 지났군요 뭐해 . 싸 이게 녀라 요들. 쇼아닌가요 지난 있겠죠 훔서서\n",
            "구프프이게 프프이게 프프생만해도 는지는 난난골라! 깊은 결참\n",
            "쉬세요 내세요 간 못답답라도 빌컨해도 싶화를 는거 찍라도 찍찍있지난 요\n",
            "10 epoch loss: 0.6264 / ppl: 1.8708\n",
            ". \n",
            "연락내 내 . \n",
            ". \n",
            "20 epoch loss: 0.5884 / ppl: 1.8010\n",
            "잘 . \n",
            "내 내 내 내 내 내 내 내 내 내 내 내 내 내 꼭 그래요 \n",
            "잘 . \n",
            "30 epoch loss: 0.5586 / ppl: 1.7482\n",
            "잘 더 . \n",
            "내 내 내 내 내 내 내 내 내 내 내 내 내 내 내 내 내 내 내\n",
            "잘 더 . \n",
            "40 epoch loss: 0.5427 / ppl: 1.7207\n",
            "잘 더 더 . \n",
            "잘되고싶잘되고싶한 로 이겠죠 . \n",
            "잘 더 . \n",
            "50 epoch loss: 0.5008 / ppl: 1.6500\n",
            "잘 더 . \n",
            "잘되고싶잘되고싶지에서만 한 곳이라면요 . \n",
            "잘 더 더 . \n",
            "60 epoch loss: 0.4613 / ppl: 1.5861\n",
            "잘 는 게 . \n",
            "잘되고싶지에서만 한 상황이네요 . \n",
            "잘 는 게 거예요 . \n",
            "70 epoch loss: 0.4167 / ppl: 1.5170\n",
            "잘 는 게 . . \n",
            "잘되고싶지에서만 한 상황이네요 . \n",
            "잘 는 게 . . \n",
            "80 epoch loss: 0.3905 / ppl: 1.4778\n",
            "연락는 게 . \n",
            "잘되고싶지에서만 할 수 있는 하면서 크게 심호흡해보세요 . \n",
            "잘 는 게 . . \n",
            "90 epoch loss: 0.3347 / ppl: 1.3976\n",
            "연락이었으면 . \n",
            "네 말씀하세요 . \n",
            "하나 바꾸는 게 수 있다는 . \n",
            "100 epoch loss: 0.2719 / ppl: 1.3125\n",
            "연락사는 는 게 수 있어요 . \n",
            "네 말씀하세요 . \n",
            "하나 바꾸는 게 수 있다는 . \n",
            "110 epoch loss: 0.2443 / ppl: 1.2768\n",
            "연락사는 참석하. \n",
            "네 말씀하세요 . \n",
            "그것을 지켜볼 수 있다는 . \n",
            "120 epoch loss: 0.1854 / ppl: 1.2037\n",
            "연락가보세요 . \n",
            "네 말씀하세요 . \n",
            "그것을 지켜볼 수 있다는 . \n",
            "130 epoch loss: 0.1581 / ppl: 1.1712\n",
            "연락가보세요 . \n",
            "나쁜 생각 하지 하지 않는 사람들이 많죠 . \n",
            "그것을 지켜볼 수 있다는 . \n",
            "140 epoch loss: 0.1275 / ppl: 1.1359\n",
            "연락가보세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "그것을 지켜볼 수 있다는 . \n",
            "150 epoch loss: 0.0981 / ppl: 1.1030\n",
            "연락가보세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "그것을 지켜볼 수 있다는 . \n",
            "160 epoch loss: 0.0816 / ppl: 1.0851\n",
            "연락사귀세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "언젠간 잊혀질거라 믿어요 . \n",
            "170 epoch loss: 0.0699 / ppl: 1.0724\n",
            "연락사귀세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "언젠간 잊혀질거라 믿어요 . \n",
            "180 epoch loss: 0.0627 / ppl: 1.0647\n",
            "연락사귀세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "언젠간 잊혀질거라 믿어요 . \n",
            "190 epoch loss: 0.0553 / ppl: 1.0568\n",
            "연락할 세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "언젠간 잊혀질거라 믿어요 . \n",
            "200 epoch loss: 0.0439 / ppl: 1.0448\n",
            "그냥 사귀세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "언젠간 잊혀질거라 믿어요 . \n",
            "210 epoch loss: 0.0438 / ppl: 1.0447\n",
            "그냥 사귀세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "언젠간 잊혀질거라 믿어요 . \n",
            "220 epoch loss: 0.0399 / ppl: 1.0407\n",
            "그냥 사귀세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "언젠간 잊혀질거라 믿어요 . \n",
            "230 epoch loss: 0.0314 / ppl: 1.0319\n",
            "그냥 사귀세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "언젠간 잊혀질거라 믿어요 . \n",
            "240 epoch loss: 0.0310 / ppl: 1.0314\n",
            "그냥 사귀세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "언젠간 잊혀질거라 믿어요 . \n",
            "250 epoch loss: 0.0250 / ppl: 1.0253\n",
            "그냥 사귀세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "언젠간 잊혀질거라 믿어요 . \n",
            "260 epoch loss: 0.0301 / ppl: 1.0306\n",
            "그냥 사귀세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "언젠간 잊혀질거라 믿어요 . \n",
            "270 epoch loss: 0.0205 / ppl: 1.0207\n",
            "그냥 사귀세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "언젠간 잊혀질거라 믿어요 . \n",
            "280 epoch loss: 0.0188 / ppl: 1.0190\n",
            "그냥 사귀세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "언젠간 잊혀질거라 믿어요 . \n",
            "290 epoch loss: 0.0170 / ppl: 1.0172\n",
            "그냥 사귀세요 . \n",
            "나쁜 생각 하지 마세요 . \n",
            "언젠간 잊혀질거라 믿어요 . \n"
          ]
        }
      ]
    }
  ]
}